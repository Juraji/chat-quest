package main

import (
	"fmt"
	"juraji.nl/chat-quest/ai"
	"log"
)

func main() {
	text := "<think>\nGiven that the `prose` package does not provide accurate token counts compared to `tiktoken`, we need to explore alternative approaches or libraries in Go that can more closely match `tiktoken`'s behavior.\n\n### Research and Considerations:\n\n1. **Alternative Libraries**:\n   - **GPT-3 Tokenizer**: There are some Go implementations of the GPT-3 tokenizer, which is similar to tiktoken. One such library is `github.com/cozmo-gpt/gpt3-tokenizer`.\n   - **Custom Implementation**: If no suitable library is found, we might need to create a custom implementation or use a Python backend service for tokenization.\n\n2. **Accuracy**:\n   - The chosen library should be able to handle templates and special characters accurately, as seen in your test case.\n\n3. **Performance**:\n   - The solution should be efficient enough to handle frequent calls, especially with debouncing in mind.\n\nGiven these points, let's explore the `gpt3-tokenizer` package as a potential alternative.\n</think>\n\n\n\n### Alternative Implementation using `gpt3-tokenizer`\n\nHereâ€™s an example implementation using the `gpt3-tokenizer` package:\n\n```go\npackage main\n\nimport (\n\t\"errors\"\n\t\"github.com/cozmo-gpt/gpt3-tokenizer\"\n)\n\n// TokenCount calculates the number of tokens in the given text using the GPT-3 tokenizer.\nfunc TokenCount(text string) (int, error) {\n\tif text == \"\" {\n\t\treturn 0, errors.New(\"empty input string\")\n\t}\n\n\t// Initialize the tokenizer\n\ttok := tokenizer.New()\n\n\t// Tokenize the text\n\ttokens := tok.Tokenize(text)\n\n\t// Return the number of tokens\n\treturn len(tokens), nil\n}\n```\n\n### Explanation:\n\n1. **Package and Imports**:\n   - The `gpt3-tokenizer` package is used for tokenization.\n\n2. **Function Definition**:\n   - `TokenCount` takes a string `text` as input and returns an integer representing the token count and an error if any.\n\n3. **Error Handling**:\n   - Checks for empty input strings to avoid unnecessary processing.\n\n4. **Tokenization**:\n   - Initializes the tokenizer.\n   - Tokenizes the input text using the `Tokenize` method.\n   - Returns the length of the tokens slice, which represents the token count.\n\n### Usage Example:\n\n```go\nfunc main() {\n\ttext := \"{{.User}}: Hey.\\n{{.Character}}: Hi! My name is {{.Character}}, you seem like a nice person, what is your name? *wags tail excitedly*\"\n\ttokenCount, err := TokenCount(text)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error calculating token count: %v\", err)\n\t}\n\tfmt.Printf(\"Token count for '%s': %d\\n\", text, tokenCount)\n}\n```\n\n### Verification:\n\nTo ensure the accuracy of the `gpt3-tokenizer` package, you can compare the token counts it produces with those from `tiktoken` using your test case. This will help verify if the library meets your requirements.\n\n### Notes:\n\n- **Debouncing**: As mentioned earlier, implement debouncing in the frontend to reduce the number of API calls.\n- **Fallback Option**: If the `gpt3-tokenizer` package does not provide accurate results, consider creating a Python microservice that uses `tiktoken` and exposing it via an HTTP endpoint. Your Go backend can then call this service for tokenization.\n\nThis approach should provide a more accurate token count compared to the `prose` package."
	tokenCount, err := ai.TokenCount(text)
	if err != nil {
		log.Fatalf("Error calculating token count: %v", err)
	}
	fmt.Printf("Token count: %d\n", tokenCount)
}
